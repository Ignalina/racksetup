---
    - name: Stop Spark master on master node
      when: inventory_hostname in groups['spark_master']
      systemd:
        name: spark-master
        state: stopped
        enabled: true

    - name: Stop Spark worker on worker nodes
      when: inventory_hostname in groups['spark_workers']
      systemd:
        name: spark-slave
        state: stopped
        enabled: true

    - name: Extract ivy cache tarball
      unarchive:
        src: "{{ iceberg_nessie_airgap_ivy_cache }}"
        dest: "{{ spark_user_registered.home }}"
        remote_src: no
        owner: "{{ spark_user }}"
        group: "{{ org_group }}"
        creates: "{{ spark_user_registered.home }}/airgap/.ivy/cache"

    - name: copy existing ivy files to new directory
      copy:
        src: "{{ spark_user_registered.home }}/.ivy/"
        dest: "{{ spark_user_registered.home }}/airgap/.ivy/"
        remote_src: yes

    - name: Delete now obselete ivy content & directory
      ansible.builtin.file:
        state: absent
        path: "{{ spark_user_registered.home }}/.ivy"

    - name: Finally move back ALL ivy cached content
      command: mv {{ spark_user_registered.home }}/airgap/.ivy {{ spark_user_registered.home }}/.ivy
      args:
        creates: "{{ spark_user_registered.home }}/.ivy"

    - name: Delete now obselete ivy content & directory
      ansible.builtin.file:
        state: absent
        path: "{{ spark_user_registered.home }}/airgap"

    - name: Start nessie
      when: inventory_hostname in groups['nessie_master']
      systemd:
        name: nessie
        state: started
        enabled: true

    - name: Insert nessie catalog into into spark-defaults
      blockinfile:
        dest: "{{ spark_home }}/conf/spark-defaults.conf"
        block: "{{ lookup('template', 'spark-defaults.conf.j2') }}"
        marker: "# {mark} ANSIBLE MANAGED BLOCK FOR SPARK ICEBERG DEFAULTS"
        owner: "{{ spark_user }}"
        group: "{{ org_group }}"
        mode: '770'

    - name: Start Spark master on worker nodes
      when: inventory_hostname in groups['spark_master']
      systemd:
        name: spark-master
        state: started
        enabled: true

    - name: Start Spark worker on worker nodes
      when: inventory_hostname in groups['spark_workers']
      systemd:
        name: spark-slave
        state: started
        enabled: true
