---
    - name: Create Spark user
      user:
        name: "{{ spark_user }}"
        group: "{{ org_group }}"
        shell: /bin/bash
        create_home: yes
      register: spark_user_registered

    - name: ensure spark directory exists
      file:
        path: "{{ spark_home }}"
        state: directory

    - name: Extract Spark tarball
      unarchive:
        src: "{{ spark_airgap_archive }}"
        dest: "{{ spark_home }}"
        remote_src: no
        owner: "{{ spark_user }}"
        group: "{{ org_group }}"
        creates: "{{ spark_home }}/conf"


    - name: ensure ivy cache directory exists
      file:
        path: "{{ spark_user_registered.home }}/.ivy/cache"
        state: directory

    - name: Extract ivy cache tarball
      unarchive:
        src: "{{ spark_airgap_ivy_cache }}"
        dest: "{{ spark_user_registered.home }}"
        remote_src: no
        owner: "{{ spark_user }}"
        group: "{{ org_group }}"
        creates: "{{ spark_user_registered.home }}/,ivy/cache"


    - name: Set Spark environment variables
      lineinfile:
        path: "{{ spark_home }}/conf/spark-env.sh"
        line: 'export SPARK_HOME={{ spark_home }}'
        create: yes
        owner: "{{ spark_user }}"
        group: "{{ org_group }}"
        mode: '0644'

    - name: Configure Spark to point to the master node
      when: inventory_hostname in groups['spark_workers']
      lineinfile:
        path: "{{ spark_home }}/conf/spark-defaults.conf"
        line: 'spark.master {{ spark_master_url }}'
        create: yes
        owner: "{{ spark_user }}"
        group: "{{ org_group }}"
        mode: '0644'

    - name: Create system systemd spark master service file
      when: inventory_hostname in groups['spark_master']
      template:
        src: "spark-master.service.j2"
        dest: /etc/systemd/system/spark-master.service

    - name: Create system systemd spark slave service file
      when: inventory_hostname in groups['spark_workers']
      template:
        src: "spark-slave.service.j2"
        dest: /etc/systemd/system/spark-slave.service


    - name: Start Spark master on master node
      when: inventory_hostname in groups['spark_master']
      systemd:
        name: spark-master
        state: started
        enabled: true

    - name: Start Spark worker on worker nodes
      when: inventory_hostname in groups['spark_workers']
      systemd:
        name: spark-slave
        state: started
        enabled: true

    - name: Label Spark worker nodes
      when: inventory_hostname in groups['spark_workers']
      command: >
        curl -X POST -d "worker={{ inventory_hostname }}" -d "label={{ ansible_hostname }}" http://{{ groups['spark_master'][0] }}:8080/label
      environment:
        SPARK_HOME: "{{ spark_home }}"
        PATH: "{{ spark_home }}/bin:{{ ansible_env.PATH }}"
