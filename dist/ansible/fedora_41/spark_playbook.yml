---
- name: Install Spark on Master and Worker nodes
  hosts: spark-cluster
  become: true
  vars_files:
     - global_vars.yml
     - secret_vars.yml
  tasks:
    - name: Create Spark group and user
      group:
        name: "{{ spark_group }}"
        state: present

    - name: Create Spark user
      user:
        name: "{{ spark_user }}"
        group: "{{ spark_group }}"
        shell: /bin/bash
        create_home: yes
      register: spark_user_registered

    - name: Extract Spark tarball
      unarchive:
        src: "{{ spark_airgap_archive }}"
        dest: "{{ spark_home }}"
        remote_src: yes
        owner: "{{ spark_user }}"
        group: "{{ spark_group }}"
        creates: "{{ spark_home }}"

    - name: Create folder for ivy cache
      file:
        path: "{{ spark_user_registered.home }}/.ivy/cache"
        recurse: yes
        state: directory
        owner: "{{ spark_user }}"
        group: "{{ spark_group }}"


    - name: Copy Sparks friends dependencies
      ansible.builtin.copy:
        src: "{{ spark_airgap_ivy_cache }}"
        dest: "{{ spark_user_registered.home }}/.ivy/cache"
        remote_src: yes
        owner: "{{ spark_user }}"
        group: "{{ spark_group }}"


    - name: Set Spark environment variables
      lineinfile:
        path: "{{ spark_home }}/conf/spark-env.sh"
        line: 'export SPARK_HOME={{ spark_home }}'
        create: yes
        owner: "{{ spark_user }}"
        group: "{{ spark_group }}"
        mode: '0644'

    - name: Configure Spark to point to the master node
      when: inventory_hostname in groups['spark-workers']
      lineinfile:
        path: "{{ spark_home }}/conf/spark-defaults.conf"
        line: 'spark.master {{ spark_master_url }}'
        create: yes
        owner: "{{ spark_user }}"
        group: "{{ spark_group }}"
        mode: '0644'

    - name: Start Spark master on master node
      when: inventory_hostname in groups['spark-master']
      systemd:
        name: spark-master
        state: started
        enabled: yes
        user: "{{ spark_user }}"
        group: "{{ spark_group }}"
        exec_start: "{{ spark_home }}/sbin/start-master.sh"

    - name: Start Spark worker on worker nodes
      when: inventory_hostname in groups['spark-workers']
      systemd:
        name: spark-worker
        state: started
        enabled: yes
        user: "{{ spark_user }}"
        group: "{{ spark_group }}"
        exec_start: "{{ spark_home }}/sbin/start-worker.sh {{ spark_master_url }}"

    - name: Label Spark worker nodes
      when: inventory_hostname in groups['spark-workers']
      command: >
        curl -X POST -d "worker={{ inventory_hostname }}" -d "label={{ ansible_hostname }}" http://{{ groups['spark-master'][0] }}:8080/label
      environment:
        SPARK_HOME: "{{ spark_home }}"
        PATH: "{{ spark_home }}/bin:{{ ansible_env.PATH }}"
